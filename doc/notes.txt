2017-02-19 - Progressive locks
------------------------------


Overview
--------

When dealing with complex structures such as trees, maintaining a write lock
on a tree during write operations is expensive because most of the time is
spent looking up the entry to modify and very little time is spent modifying
the entry, so during this time no read operation may be performed. In addition,
there exist some complex structures which support atomic operations on partial
areas, but for which other operations require global consistency. Everything
involving ordered writes of multiple fields in a struct falls into this
category.

The approach taken here is to keep locks loose in general and to tighten them
up when approaching the critical section, hence the name "progressive locks".
All these locks are implemented as includable C macros so the only thing a
program needs to use them is to include "plock.h" and make use of the various
pl_* macros described below.


Principles of operations
------------------------

Progressive locks have 5 states :

  - U: unlocked      : nobody claims the lock
  - R: read-locked   : some users are reading the shared resource
  - S: seek-locked   : reading is OK but nobody else may seek nor write
  - W: write-locked  : exclusive access for writing (direct or after S)
  - A: atomic        : some atomic updates are being performed

The U, R and W state are the common states for classical R/W locks. The S state
is an intermediary step between R and W, which still allows readers to enter,
but rejects other W and S requests and guarantees a quick upgrade to (as well
as return from) the W state. The S lock also makes it possible to implement
some "lockless" operations following a "single-writer multiple-readers" model
where a single careful writer can perform changes without preventing readers
from accessing the data. The A state is for atomic operations mainly consisting
in ordered writes, that can be performed in parallel but must not be mixed with
R, S nor W.

The S lock cannot be taken if another S or W lock is already held. But once the
S lock is held, the owner is automatically granted the right to upgrade it to W
without checking for other writers. And it can take and release the W lock
multiple times atomically if needed. It must only wait for last readers to
leave.

The A lock supports concurrent write accesses and is used when certain atomic
operations can be performed on a structure which also supports non-atomic
operations. It is exclusive with the other locks. It is weaker than the S/W
locks (S being a promise of upgradability), and will wait for any readers to
leave before proceeding.

The rights and expectations these locks impose to their users are the
following :

  - unlocked (U)
    - nobody may perform visible modifications to the protected area at all
    - anybody can read the protected area at their own risk
    - anybody may immediately turn the lock to any other state

  - read-locked (R)
    - requester must wait for writers to leave before being granted the lock
    - owner may read any location from the protected structure without any
      requirement for ordering ;
    - others may read any location from the protected structure without any
      requirement for ordering ;
    - others may also be granted an R lock
    - one other user may also be granted an S lock
    - one other may take a W lock but will first have to wait for all readers
      to leave before proceeding with writes ;

  - seek-locked (S)
    - requester must wait for writers and seekers to leave before being granted
      the lock
    - owner may read any location from the protected structure without any
      requirement for ordering ;
    - others may read any location from the protected structure without any
      requirement for ordering ;
    - others may also be granted an R lock
    - owner may upgrade the lock to a W lock at any instant without prior
      notification ;
    - owner must wait for readers to leave after the lock is upgraded before
      performing any write ;
    - owner may release the lock without performing an upgrade ;
    - owner may also downgrade the S lock to an R lock ;

  - write-locked (W)
    - requester must wait for writers and seekers to leave before being granted
      the lock (this is guaranteed when upgrading from S)
    - others may not try to grab any lock once this lock is held
    - the lock is granted once all other users have left
    - owner may perform any modification to the protected structure ;
    - others may not access the protected structure at all ;
    - owner may downgrade the lock to an S lock ;
    - owner may downgrade the lock to an R lock ;

  - atomic (A)
    - requester must wait for writers and seekers to leave before being granted
      the lock, but doesn't exclude other write-atomic users ;
    - the lock is granted once all other users have left
    - owner is not guaranteed to be alone since other users may hold the A lock
      in parallel and perform modifications at the same time ; observations and
      retries might be necessary to complete certain operations ;
    - owner may only carefully apply modifications to the protected structure
      using atomic operations and memory barriers in a way that is compatible
      with its own usage ;
    - others may only carefully apply modifications to the protected structure
      using atomic operations and memory barriers in a way that is compatible
      with others' usage ;
    - the protections involved with this type of lock are 100% application
      specific. Most commonly this will be used to reinitialize some elements,
      release a series of pointers using atomic operations and all compatible
      functions will use this lock instead of any of the 3 above.

The compatiblity between all types of locks is given by the following matrix
which indicates how many locks of each type may be held for each lock state :


                           Concurrent accesses allowed
                Current
                state   |   U  |   R  |   S  |   W  |   A
                   -----+------+------+------+------+-------
                     U  | 0..N | 0..N | 0..1 | 0..1 | 0..N
                   -----+------+------+------+------+-------
                     R  | 0..N | 0..N | 0..1 |   0  |   0
                   -----+------+------+------+------+-------
                     S  | 0..N | 0..N |   0  |   0  |   0
                   -----+------+------+------+------+-------
                     W  | 0..N |   0  |   0  |   0  |   0
                   -----+------+------+------+------+-------
                     A  | 0..N |   0  |   0  |   0  | 0..N
                   -----+------+------+------+------+-------


Implementation
--------------

All upgrade attempts may be reverted and are reverted in case of failure, so
in the worst case very few concurrent accesses are observed, and the bits read
represent a combination of a granted state and an attempt to take a lock. Lock
operations take care of checking the lock's value without locking prior to
trying to grab it so that write operations do not happen while a lock is held.

Most lock upgrades are performed in two phases :
  - request the lock
  - wait for previous incompatible users to leave

The locks are implemented using cumulable bit fields representing from the
lowest to the highest bits :
  - the number of readers (read, seek, write)
  - the number of seek requests
  - the number of write requests

Each regular lock (R, S, W) counts as a reader. Since all of them may operate
on a concurrent read, the maximum number of concurrent threads supported is
dictated by the number of bits used to encode the readers.

Since the writers are totally exclusive to any other activity, they require the
same number of bits in order to accept the worst possibly imaginable scenario
where all threads would request a write lock at the exact same instant so the
number of bits used to represent writers is the same as the number used to
represent the number of readers.

The number of seek requests remains on a low bit count and this number is
placed just below the write bit count so that if it overflows, it temporarily
overflows into the write bits and appears as requesting an exclusive write
access. This allows the number of seek bits to remain very low, 1 technically,
but 2 to avoid needless lock/unlock sequences during common conflicts.

In terms of representation, we have this :
  - R lock is made of the R bit
  - S lock is made of S + R bits
  - W lock is made of W + S + R bits
  - A lock is made of W bits only

Due to W being made of W + S + R, and S overflowing into W, each time a W lock
is directly taken, both W and S bits are added resulting in the W field growing
faster than the number of write requests. Indeed, with two bits for S below W,
the W:S word is increased by 0b101 = 5 while W represents 1/4 of the W:S word,
so each writer consumes 5/4 of a position. But given that 5 doesn't divide any
power-of-two quantity, we're guaranteed to always keep at least one non-null
bit in the W part of the word for any supported number of writers, and given
that the W lock is stronger than the S lock, other access types are protected.
Having only the W bits set in W:S could be confused with the A lock except that
the A lock doesn't hold the R bits and is exclusive with regular locks so this
situation is unambiguous as well.

In practice, it is useful to understand all states that can be observed in the
lock, including the transient ones shown below. "N" means "anything greater
than zero. "M" means "greater than 1 (many)". "X" means "anything including
zero".

    W   S   R   State
  ----+---+---+------------
    0 | 0 | 0 | Unlocked
    0 | 0 | N | N readers (R)
    0 | 1 | N | one seeker (S) + (N-1) readers (R)
    0 | M | X | one seeker (S) + new seeker attempt (transient)
    1 | 1 | 1 | one writer (W)
    1 | 1 | M | R attempt while W or W attempt while R (transient)
    N | 0 | 0 | N atomic writers (A)
    N | 0 | N | A attempt while R or R attempt while A (transient)
    N | N | N | A attempt while S or S attempt while A (transient)
    M | M | N | A attempt while W or W attempt while A (transient)

The lock can be upgraded and downgraded between various states at the demand of
the requester :

  - U<->A : pl_take_a() / pl_drop_a()   (adds/subs W)
  - U<->R : pl_take_r() / pl_drop_r()   (adds/subs R)
  - U<->S : pl_take_s() / pl_drop_s()   (adds/subs S+R)
  - U<->W : pl_take_w() / pl_drop_w()   (adds/subs W+S+R)
  - S<->W : pl_stow()   / pl_wtos()     (adds/subs W)
  - S->R  : pl_stor()                   (subs S)
  - W->R  : pl_wtor()                   (subs W+S)

Other transitions are permitted in opportunistic mode, such as R to A, but are
not guaranteed to succeed.

Progressive locks are defined to be used on various data types including 32 and
64 bit integers as well as pointers. Special care was taken not to touch the
two lowest bits of the locked data, which remain available for the application,
eg for typed pointers or end of list markers. With the lowest two bits removed,
we can have this distribution :

- for 32-bit locks :
  - 31..18 : 14 bits for writers
  - 17..16 : 2  bits for seekers
  - 16..2  : 14 bits for users
  -  1..0  : 2 bits for the application
  => up to 16383 users (readers/seekers/writers)

- for 64-bit locks :
  - 63..34 : 30 bits for writers
  - 33..32 : 2  bits for seekers
  - 31..2  : 30 bits for users
  -  1..0  : 2 bits for the application
  => up to ~1.07B users (readers/seekers/writers)


Application to a tree
---------------------

A typical use case is for ebtrees in order to secure the following operations :
  - node *insert(tree, node) : insert node <node> into tree <tree>, return
                               <node> or another one if unique bit is set
  - node *lookup(tree, key)  : lookup value <key> in tree <tree>, return the
                               first matching node or NULL
  - node *delete(tree, node) : delete node <node> from tree <tree>. Returns the
                               node if properly deleted or NULL if the node was
                               not there.
  - node *pick(tree, key)    : lookup value <key> in tree <tree>, detach it from
                               the tree and return it, or return NULL if not
                               found.

Implementation :
  - insert(tree, node) {
        pl_take_s(tree); // take S
        walk_down_to(node->key);
        pl_stow(tree);   // upgrade to W
        insert_node_here(node);
        pl_drop_w(tree); // drop
    }

  - lookup(tree, key) {
        pl_take_r(tree); // take R
        walk_down_to(key);
        pl_drop_r(tree); // drop
    }

  - delete(tree, node) {
        pl_take_w(tree);  // take W
        delete_node(node);
        pl_drop_w(tree);  // drop
    }

  - pick(tree, key) {
        pl_take_s(tree);  // take S
        walk_down_to(key);
        pl_stow(tree);    // upgrade to W
        delete_node(node);
        pl_wtos(tree);    // drop
    }

For some applications like a scheduler, all operations will be either pick() or
insert(). All of them will be exclusive between each other. For each entry,
there will be exactly one insert() and one pick(). The pick() operation here is
problematic as it will serialize all accesses. An alternative approach consists
in retryable lookups + deletes :

   do {
      node = lookup_next(tree);
   } while (node && !delete(tree, node));

This will also ensure atomicity during the pick up period while not locking the
whole tree during the descent. And since the lookup() is compatible with the
S lock used during the descent for the insert() operation, most operations
can be performed in parallel.

Some operations may be performed in multiple steps without completely unlocking
the tree. For example in order to use lookup_next(), it might be required that
the previous element is returned with the tree still locked. But depending on
what is supposed to be performed, different types of locks might be needed.
For example, in order to only dump a tree, it is sufficient to lock the tree
read_only and jump between nodes using lookup_next(). However in order to
perform a two-step lookup+update as above, it is mandatory to leave the tree
in an upgradable locked state in order to guarantee that no other subsequent
modification will be performed nor could block. Last, a complete cleanup of a
tree could consist in looking up the first element, locking the tree for writes
and performing deletes alternating with lookup_next().

For this reason it appears that some operations are relative to existing nodes
and do not affect the locking at all :
  - lookup_next()
  - lookup_prev()

It's the caller's responsibility to ensure that the initial node is valid and
that these functions are used with appropriate locking.

Then there are some lookup functions applying to the tree :

  - lookup_first(), lookup_last()
  - lookup_key(), ...

Such functions may leave the tree locked in R or S states.

Then some functions modify the tree and may leave it in a still modifiable
state because the W lock has not yet been released :

  - pick(), insert(), delete()


Data protection in a tree
-------------------------

The method described here only applies to the tree structure, but doesn't
prevent data from being modified or even released during the lookups. It is
important to distinguish two things :

  - the tree structure (linking between nodes)
  - the data integrity (no use-after-free etc)

The tree is made of nodes linked together, and the locking ensures that no node
is visited during a tree traversal after being removed from the tree. Thus from
a tree structure perspective it is safe to free a node that was deleted from
the tree. However that doesn't mean that there's no other user of this node, eg
consecutive to a successful lookup operation, so it is up to the application to
ensure proper refcounting on the data.

A typical lookup_next() operation cannot be performed on a node that was
removed by another user, regardless of the fact that it has not necessarily
been freed. And conversely it's not acceptable to leave a node in the tree
waiting for its refcount to be zeroed before being deleted. If a lookup_next()
operation has to be used, then it looks like a reasonable expectation that the
previous lookup leaves the tree locked against modifications.

It does not seem necessary to implement any form of refcounting between the
tree and the data stored in the tree. While the tree structure relies on the
nodes themselves, there is no reason for any access to the tree to be done in
a "degraded" mode where the tree is inconsistent. Thus if all tree access
operations remain valid, it's up to the application to add proper refcounting
to its data nodes upon lookups to avoid the risk of concurrent use and removal.

A typical set of "get", "put", "del" operations could be implemented like this :

   node *get_key(tree, key) {
       node = lookup_locked(tree, key);
       if (node)
           node->refcount++;
       unlock_tree(tree);
       return node:
   }

   put_node(node) {
       node->refcount--;
   }

   del_node(tree, node) {
       delete_node(tree, node);
   }

It *may* make sense to decide that a node stored in the tree has 1 added to its
refcount but that's only a matter of implementation choice as nothing makes
this a necessity :

   node *get_key(tree, key) {
       node = lookup_locked(tree, key);
       if (node)
           node->refcount++;
       unlock_tree(tree);
       return node:
   }

   put_node(node) {
       if (!node->refcount--)
          free(node);
   }

   del_node(tree, node) {
       delete_node(tree, node);
       if (!node->refcount--)
          free(node);
   }

